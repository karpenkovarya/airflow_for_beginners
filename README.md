This is a small example of the workflow built with Apache Airflow.

The goal is to set up a data pipline to get a fresh portion of Stack Overflow questions with tag `pandas` to our mailbox daily.

A small python script could do the job, but for the learning purposes we choose to overengineer it.

By writing this workflow we will learn the main concepts of Apache Airflow, such as:
    
* Operators
* DAG
* Tasks
* Hooks
* Variables
* Connections
* XComs

Happy learning ğŸ¤“

###Helpful resources

ğŸ“ [Apache Airflow Documentation](https://airflow.apache.org/)

#### Apache Airflow tutorials for beginners

ğŸ“ [Apache Airflow Tutorial for Data Pipelines](https://blog.godatadriven.com/practical-airflow-tutorial)

ğŸ“ [Apache Airflow for the confused](https://medium.com/nyc-planning-digital/apache-airflow-for-the-confused-b588935669df)

ğŸ“ [Airflow: Tutorial and Beginners Guide](https://www.polidea.com/blog/apache-airflow-tutorial-and-beginners-guide/)

ğŸ“ [ETL Pipelines With Airflow](http://michael-harmon.com/blog/AirflowETL.html)


#### Some more

ğŸ“° [ETL best principles](https://gtoonstra.github.io/etl-with-airflow/principles.html)

ğŸ“ [Getting Started with Airflow Using Docker](http://www.marknagelberg.com/getting-started-with-airflow-using-docker/)

ğŸ§ [Putting Airflow Into Production](https://overcast.fm/+H1YNx1QJE)

ğŸ“ [How to configure SMTP server for apache airflow](https://stackoverflow.com/questions/51829200/how-to-set-up-airflow-send-email)


If you have any questions or would like to get in touch with me, please drop me a message to `hello@varya.io`
